{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWa7Xo6PkIl3",
        "outputId": "e150aaca-6a7e-456b-e100-e3cd2040e766"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "import torchvision\n",
        "from torchvision import models, datasets, transforms\n",
        "import torchvision.transforms as T\n",
        "from skimage.metrics import mean_squared_error, structural_similarity\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "torch.manual_seed(50)\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjKWqs2akepH",
        "outputId": "248e5f68-6414-4e11-8ad1-37e2df07469d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
        "tp = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "tt = transforms.ToPILImage()\n",
        "\n",
        "device = \"cpu\"\n",
        "# if torch.cuda.is_available():\n",
        "#     device = \"cuda\"\n",
        "# print(\"Running on %s\" % device)\n",
        "\n",
        "def label_to_onehot(target, num_classes=100):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AorI020iVjjS"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-.5, .5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        act_relu=nn.ReLU\n",
        "        act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.body = nn.Sequential(\n",
        "        nn.Conv2d(3, 12, kernel_size=5, padding=5//2, stride=2,padding_mode='zeros'),\n",
        "        act,  \n",
        "        nn.Conv2d(12, 22, kernel_size=5,padding=5//2, stride=2,padding_mode='zeros'),\n",
        "        act_relu(),\n",
        "        nn.Conv2d(22, 3, kernel_size=5, padding=5//2, stride=1,padding_mode='zeros'),\n",
        "        act_relu(),\n",
        "        nn.Conv2d(3, 3, kernel_size=5, padding=5//2, stride=1,padding_mode='zeros'),\n",
        "        act_relu(),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(192, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out=out.view(out.size(0),-1)\n",
        "        out=self.fc(out)\n",
        "        return out,x\n",
        "net = LeNet().to(device)\n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8mSgR4GClV-8",
        "outputId": "abe34e49-905b-4d53-f8cb-d7cf1347e9b1"
      },
      "outputs": [],
      "source": [
        "######### Feed the image to the network and compute gradients #########\n",
        "img_index = 12\n",
        "gt_data = tp(dst[img_index][0]).to(device)\n",
        "gt_data = gt_data.view(1, *gt_data.size())\n",
        "gt_label = torch.Tensor([dst[img_index][1]]).long().to(device)\n",
        "gt_label = gt_label.view(1, )\n",
        "gt_onehot_label = label_to_onehot(gt_label, num_classes=100)\n",
        "\n",
        "\n",
        "out,org_x = net(gt_data)\n",
        "y = criterion(out, gt_onehot_label)\n",
        "\n",
        "dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "\n",
        "# Extract the gradients and initial parameters\n",
        "original_dy_dx = [_.numpy() for _ in dy_dx]\n",
        "param = [i.detach().numpy() for i in net.parameters() if i.requires_grad]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to return the details of the layers (e.g., input dimensions, number of filters, padding, stride) for use at runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inspect_model(model,x_dim=32):\n",
        "    conv_layers = []\n",
        "    fc_layers = []\n",
        "    parmeter_index=0   # Hold the index of the parameters of each layer\n",
        "    input_dim=x_dim\n",
        "    input_dim_fc=0\n",
        "    act_fun=''\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            output_dim=int((input_dim+2*module.padding[0]-module.kernel_size[0])/module.stride[0])+1\n",
        "            layer_details = {\n",
        "                'param_index':parmeter_index,\n",
        "                'input_channel': module.in_channels,\n",
        "                'number_filters': module.out_channels,\n",
        "                'stride': module.stride[0],\n",
        "                'padding': module.padding[0],\n",
        "                'kernel': module.kernel_size[0],\n",
        "                'input_dim':input_dim,\n",
        "                'output_dim':output_dim,\n",
        "                'act_fun':act_fun\n",
        "            }\n",
        "            conv_layers.append(layer_details)\n",
        "            input_dim=output_dim\n",
        "            input_dim_fc=input_dim**2*module.out_channels\n",
        "            parmeter_index+=2\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            layer_fc_details = {\n",
        "                'param_index':parmeter_index,\n",
        "                'input_dim':(input_dim_fc),\n",
        "                'output_dim':module.out_features\n",
        "            }\n",
        "            fc_layers.append(layer_fc_details)\n",
        "            input_dim_fc=module.out_features\n",
        "            parmeter_index+=2\n",
        "        elif isinstance(module, (nn.ReLU, nn.LeakyReLU, nn.Sigmoid, nn.Tanh)):\n",
        "            act_fun=str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
        "            conv_layers[-1]['act_fun']=act_fun\n",
        "    return conv_layers,fc_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to compute the gradient w.r.t the input of the convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def drive_gradient(input_shape,weights,output_gradients,stride,padding):\n",
        "    weights = torch.tensor(weights, requires_grad=True)\n",
        "    input_tensor = torch.randn(input_shape, requires_grad=True)\n",
        "    dL_dY = output_gradients\n",
        "    \n",
        "    # dummy forward pass to build the computational graph\n",
        "    output = F.conv2d(input_tensor, weights, stride=stride, padding=padding)\n",
        "    output.backward(dL_dY)\n",
        "    dL_dX= input_tensor.grad\n",
        "    return dL_dX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to reconstruct the input of a convolutional layer using gradient constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def construt_input_using_gradients(num_f,num_c,dim_x,output_gradient,weight_gradeint,padding,stride,kernal=5):\n",
        "    input_matrix=dim_x*dim_x\n",
        "    pad_dim=dim_x+2*padding\n",
        "    a=np.array(output_gradient)\n",
        "    Filters_gradients=np.array(weight_gradeint).reshape(num_f,num_c,kernal,kernal)\n",
        "    x=[]\n",
        "    indices=[]\n",
        "    for n in range(num_c):\n",
        "        cord_a=[]\n",
        "        cord_b=[]\n",
        "        rank=0\n",
        "        for i in range(num_f):\n",
        "            for k in range(kernal):\n",
        "                for l in range(kernal):\n",
        "                    if(rank==input_matrix):\n",
        "                        break\n",
        "                    cord_b.append(Filters_gradients[i][n][k][l])\n",
        "                    array_gradients=np.zeros(pad_dim**2).reshape(pad_dim,pad_dim)\n",
        "                    array_gradients[k:k+dim_x:stride,l:l+dim_x:stride]=a[i:i+1]\n",
        "                    cord_a.append(array_gradients[padding:padding+dim_x,padding:padding+dim_x].reshape(input_matrix))\n",
        "                    if(n==0):\n",
        "                        current_rank=np.linalg.matrix_rank(cord_a)\n",
        "                        if (current_rank==rank):\n",
        "                            indices.append(i*25+k*5+l)\n",
        "                            cord_a=cord_a[:-1]\n",
        "                            cord_b=cord_b[:-1]\n",
        "                        rank=current_rank\n",
        "        if n!=0:\n",
        "            cord_a=np.delete(cord_a,indices,axis=0)\n",
        "            cord_b=np.delete(cord_b,indices,axis=0)\n",
        "            cord_a=cord_a[0:input_matrix]\n",
        "            cord_b=cord_b[0:input_matrix]\n",
        "        sol=np.linalg.solve(cord_a,cord_b)\n",
        "        sol2=sol.reshape(dim_x,dim_x)\n",
        "        x.append(sol2)\n",
        "    x=np.array(x).reshape(num_c,dim_x,dim_x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to reconstruct the input of a convolutional layer using weight constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def construt_input_using_weights(num_filters,num_c,dim_x,Y,W,pad,stride,kernal=5):\n",
        "    a=[]\n",
        "    b=[]\n",
        "    dim=dim_x**2\n",
        "    pdim=dim_x+pad\n",
        "    for n in range(num_filters):\n",
        "        q=0\n",
        "        for k in range(0,dim_x,stride):\n",
        "            v=0\n",
        "            for l in range(0,dim_x,stride):\n",
        "                a_row=np.zeros(dim_x**2*num_c)\n",
        "                for c in range(num_c):\n",
        "                    x1_=np.zeros((dim_x+2*pad)**2).reshape(dim_x+2*pad,dim_x+2*pad)\n",
        "                    x1_[k:k+kernal,l:l+kernal]=W[n][c]\n",
        "                    a_row[c*dim:dim+c*dim]=x1_[pad:pdim,pad:pdim].reshape(dim)\n",
        "                a.append(a_row)\n",
        "                b.append(Y[n][q][v])\n",
        "                v+=1\n",
        "            q+=1\n",
        "    sol=np.linalg.solve(a[:dim_x**2*num_c],b[:dim_x**2*num_c]).reshape(num_c,dim_x,dim_x)\n",
        "    return sol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct the input and the gradient w.r.t the input of the first fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_layers,fc_layers=inspect_model(net)\n",
        "FC=fc_layers[0]\n",
        "in_dim=FC['input_dim']\n",
        "out_dim=FC['output_dim']\n",
        "w_index=FC['param_index']\n",
        "b_index=w_index+1\n",
        "#Compute The gradient w.r.t input to FC sum ( bias * weight)\n",
        "\n",
        "FC_input_gradient=np.zeros(in_dim)\n",
        "FC_input_values=np.zeros(in_dim)\n",
        "for i in range(out_dim):\n",
        "    for n in range(in_dim):\n",
        "      FC_input_gradient[n]+= original_dy_dx[b_index][i]*param[w_index][i][n]\n",
        "      \n",
        "# Compute the values of the input of FC ( weigh/bias)\n",
        "\n",
        "for n in range(in_dim):\n",
        "  for k in range(out_dim):\n",
        "    if original_dy_dx[b_index][k]!=0:\n",
        "      FC_input_values[n]= original_dy_dx[w_index][k][n]/original_dy_dx[b_index][k]\n",
        "\n",
        "Computed_gradients= FC_input_gradient.copy()\n",
        "Computed_values=FC_input_values.copy()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct the input and compute the gradient with respect to the input of the convolutional layers:<br>\n",
        "For each layer :<br>\n",
        "    1- Propagating the precomputed gradient of the subsequent layer through the activation function<br>\n",
        "    2- Constructing the input based on gradient constraints<br>\n",
        "    3-Computing the gradient with respect to the input<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "UE93IXSq41tt",
        "outputId": "3811071d-3de3-4ef4-f488-088890a5c2c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ta18336\\AppData\\Local\\Temp\\ipykernel_35296\\118438635.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output_gradient=torch.tensor(output_gradient).reshape(num_filters,out_dim,out_dim)\n"
          ]
        }
      ],
      "source": [
        "for n in range(len(cnn_layers)-1,-1,-1):\n",
        "  # Extract the layer setting \n",
        "  cnn=cnn_layers[n]\n",
        "  num_filters=cnn['number_filters']\n",
        "  num_c=cnn['input_channel']\n",
        "  dim_x=cnn['input_dim']\n",
        "  w_index=cnn['param_index']\n",
        "  weight_gradient=original_dy_dx[w_index]\n",
        "  output_gradient= Computed_gradients\n",
        "  padding=cnn['padding']\n",
        "  stride=cnn['stride']\n",
        "  out_dim=cnn['output_dim']\n",
        "  act_fun=cnn['act_fun']\n",
        "  # Propagate the gradient through the activation Funciton\n",
        "  Computed_values=Computed_values.reshape(out_dim**2*num_filters)\n",
        "  output_gradient=output_gradient.reshape(out_dim**2*num_filters)\n",
        "  output_values=Computed_values.reshape(out_dim**2*num_filters)\n",
        "  for i in range(out_dim**2*num_filters):\n",
        "    if(act_fun=='ReLU'):\n",
        "      if np.round(Computed_values[i],7)<=0:\n",
        "        output_gradient[i]=0\n",
        "    elif(act_fun=='LeakyReLU'):\n",
        "      if np.round(Computed_values[i],7)<0:\n",
        "        output_gradient[i]=output_gradient[i]*0.2\n",
        "        output_values[i]=output_values[i]/0.2\n",
        "  \n",
        "  if(n!=0):   # check if reached the first convloution layer        \n",
        "    output_gradient=torch.tensor(output_gradient).reshape(num_filters,out_dim,out_dim)\n",
        "\n",
        "    # construct the output_values of the layer\n",
        "    x=construt_input_using_gradients(num_filters,num_c,dim_x,output_gradient,weight_gradient,padding,stride)\n",
        "    # Compute the gradient w.r.t input of the layer\n",
        "    dL_dX_CNN= drive_gradient(x.shape,param[w_index],output_gradient,stride,padding)\n",
        "\n",
        "    Computed_gradients= dL_dX_CNN\n",
        "    Computed_values=x\n",
        "  else:      # in case of the first convloution layer we construct the input using weight constrains\n",
        "    Y=output_values.reshape(num_filters,out_dim,out_dim)\n",
        "    weights = param[w_index] \n",
        "    bias=param[w_index+1]\n",
        "    for i in range(num_filters):\n",
        "        Y[i]=Y[i]-bias[i]\n",
        "    sol= construt_input_using_weights(num_filters,num_c,dim_x,Y,weights,padding,stride)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View Reconstructed Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ta18336\\AppData\\Local\\Temp\\ipykernel_35296\\3002170673.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  oringinal_val=torch.tensor(org_x).reshape(3,32,32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAELCAYAAABEYIWnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0DElEQVR4nO3de3Cc9XU+8PO+e79IWkmru2xJFgaMwQG7kDZg3EAIcXACCYVCiIMNDGGSttBJmE6bJhg3oW3oNHQ8QyElJemkk2makFtTIAk4OGTS/FIuvt+xZEuWLWm1K+399n5/fzBWEfZzJNYBR36fz0xmgo523/vx12s9OpYxxggRERG5ln2md4CIiIjOLC4GiIiIXI6LASIiIpfjYoCIiMjluBggIiJyOS4GiIiIXI6LASIiIpfjYoCIiMjluBggIiJyOS4G5rENGzaIZVk1vfbrX/+6WJYlAwMDv92deoOBgQGxLEu+/vWvv23bICKqxen0z7MRFwNnyM6dO+XjH/+4dHV1SSAQkM7OTrnttttk586dZ3rXiIjk6NGjsmHDBnn11VddvQ9uwcXAGfDUU0/J8uXL5bnnnpP169fLo48+Knfeeads3rxZli9fLt/73vfm9D5//dd/Lfl8vqZ9WLt2reTzeenp6anp9UR0djt69Kg8+OCDZ3wxcKb3wS28Z3oH3ObgwYOydu1aWbRokWzZskVaWlqma/fee6+sXLlS1q5dK9u2bZNFixad8j2y2axEIhHxer3i9dZ2CT0ej3g8nppeS0S6E8+om+RyOQmHw2d6N6hG/GTgHfbwww9LLpeTr371qzMWAiIi8XhcHn/8cclms/LlL39ZRP7v37V27dolH/vYx6SxsVGuuOKKGbU3yufz8md/9mcSj8elrq5OPvzhD8vw8LBYliUbNmyY/r5T/cxAb2+vrFmzRl588UW57LLLJBgMyqJFi+Tf/u3fZmxjYmJCPvvZz8pFF10k0WhU6uvrZfXq1bJ169bf4pkimh+0Z/Sb3/ymrFixQkKhkDQ1Ncktt9wiR44cOek9fv3rX8sHP/hBaWxslEgkIsuWLZN/+qd/mvE9zz//vKxcuVIikYjEYjG5/vrrZffu3afclwMHDsi6deskFotJQ0ODrF+/XnK53Izv/elPfypXXHGFxGIxiUajct5558lf/dVfiYjIz3/+c7n00ktFRGT9+vViWdaMn//5wz/8Q7nwwgvlpZdekiuvvFLC4fD0a9/ca07o7e2VdevWzfhaKpWSP//zP5fe3l4JBALS3d0tn/jEJ2R8fHzWfThx3j7wgQ9IQ0ODhMNhWbVqlfzyl788adsvvviiXHrppRIMBqW/v18ef/zxk77H7fjJwDvsRz/6kfT29srKlStPWb/yyiult7dXfvzjH8/4+k033SSLFy+Whx56SLSp0+vWrZNvf/vbsnbtWvn93/99eeGFF+S6666b8/4dOHBA/uiP/kjuvPNOuf322+Vf//VfZd26dbJixQpZunSpiIi89tpr8v3vf19uuukm6evrk+PHj8vjjz8uq1atkl27dklnZ+ect0d0tnjzM/qlL31JPv/5z8vNN98sd911l4yNjcmmTZvkyiuvlFdeeUVisZiIvP6H8po1a6Sjo0PuvfdeaW9vl927d8t//dd/yb333isiIj/72c9k9erVsmjRItmwYYPk83nZtGmTXH755fLyyy9Lb2/vjH25+eabpa+vT/72b/9WXn75ZXniiSektbVV/v7v/15EXv+ZpTVr1siyZctk48aNEggE5MCBA9N/kC5ZskQ2btwoX/jCF+Tuu++e7lfvec97preRSCRk9erVcsstt8jHP/5xaWtre0vnK5PJyMqVK2X37t1yxx13yPLly2V8fFx++MMfytDQ0Kz78Pzzz8vq1atlxYoV8sADD4ht2/Lkk0/KVVddJb/4xS/ksssuExGR7du3y/vf/35paWmRDRs2SKVSkQceeOAt7+9Zz9A7JpVKGREx119/vfp9H/7wh42ImKmpKfPAAw8YETG33nrrSd93onbCSy+9ZETE3HfffTO+b926dUZEzAMPPDD9tSeffNKIiDl06ND013p6eoyImC1btkx/bXR01AQCAfOZz3xm+muFQsFUq9UZ2zh06JAJBAJm48aNM74mIubJJ59Uj5doPjvVMzowMGA8Ho/50pe+NON7t2/fbrxe7/TXK5WK6evrMz09PSaZTM74Xsdxpv//xRdfbFpbW00ikZj+2tatW41t2+YTn/jESftyxx13zHivj3zkI6a5uXn6v7/yla8YETFjY2PwuH7zm9/A53fVqlVGRMxjjz12Uu3NveaEnp4ec/vtt0//9xe+8AUjIuapp5466XtPHDvaB8dxzOLFi82111474zzlcjnT19dnrrnmmumv3XDDDSYYDJrBwcHpr+3atct4PB7DPwL/D/+Z4B2UTqdFRKSurk79vhP1qamp6a/dc889s77/M888IyIin/rUp2Z8/U//9E/nvI8XXHDBjE8tWlpa5LzzzpPXXntt+muBQEBs+/Vbp1qtSiKRmP6Y8eWXX57ztojOJm98Rp966ilxHEduvvlmGR8fn/5fe3u7LF68WDZv3iwiIq+88oocOnRI7rvvvulPCk448U+AIyMj8uqrr8q6deukqalpur5s2TK55ppr5L//+7/VfRERWblypSQSiemecmJbP/jBD8RxnJqONxAIyPr162t6rYjId7/7XXnXu94lH/nIR06qzRb5e/XVV2X//v3ysY99TBKJxPT5zWazcvXVV8uWLVvEcRypVqvy7LPPyg033CALFy6cfv2SJUvk2muvrXnfz0ZcDLyDTvwhf2JRgJxq0dDX1zfr+w8ODopt2yd97znnnDPnfXzjA3NCY2OjJJPJ6f92HEe+8pWvyOLFiyUQCEg8HpeWlhbZtm2bTE5OznlbRGeTNz53+/fvF2OMLF68WFpaWmb8b/fu3TI6Oioir/9AsYjIhRdeCN93cHBQRETOO++8k2pLliyZ/kPwjd78HDc2NoqITD/Hf/zHfyyXX3653HXXXdLW1ia33HKLfPvb335LC4Ouri7x+/1z/v43O3jwoHrcmv3794uIyO23337S+X3iiSekWCzK5OSkjI2NST6fl8WLF5/0Hqc6n27Gnxl4BzU0NEhHR4ds27ZN/b5t27ZJV1eX1NfXT38tFAq93bsnIgITBuYNP6fw0EMPyec//3m544475G/+5m+kqalJbNuW++67r+a/ZRDNd298Rh3HEcuy5Omnnz7lMxWNRt/WfZntOQ6FQrJlyxbZvHmz/PjHP5ZnnnlG/uM//kOuuuoq+clPfjKnpNFb7UnVavUtfb/mRJ95+OGH5eKLLz7l90SjUSkWi7+1bZ7tuBh4h61Zs0b+5V/+RV588cXpnzh+o1/84hcyMDAgn/zkJ9/ye/f09IjjOHLo0KEZK+EDBw6c1j6/2Xe+8x1573vfK1/72tdmfD2VSkk8Hv+tbotoPurv7xdjjPT19cm5556rfp+IyI4dO+R973vfKb/nxO8C2bt370m1PXv2SDwerynGaNu2XH311XL11VfLP/7jP8pDDz0kn/vc52Tz5s3yvve9r+bfztfY2CipVGrG10qlkoyMjMz4Wn9/v+zYsUN9L7QPJ85bfX09PG8ir/8zZygUmv4k4Y1OdT7djP9M8A67//77JRQKySc/+UlJJBIzahMTE3LPPfdIOByW+++//y2/94l/A3v00UdnfH3Tpk217/ApeDyekxIN//mf/ynDw8O/1e0QzVcf/ehHxePxyIMPPnjSs2KMmX72ly9fLn19ffLII4+c9Afoidd1dHTIxRdfLN/4xjdmfM+OHTvkJz/5iXzwgx98y/s3MTFx0tdO/A37xN+mTyww3rxfs+nv75ctW7bM+NpXv/rVkz4ZuPHGG2Xr1q2n/CVrJ44d7cOKFSukv79f/uEf/kEymcxJrx8bGxOR13vVtddeK9///vfl8OHD0/Xdu3fLs88++5aO62zHTwbeYYsXL5ZvfOMbctttt8lFF10kd955p/T19cnAwIB87Wtfk/HxcfnWt741vfJ9K1asWCE33nijPPLII5JIJKajhfv27ROR2X8oZ67WrFkjGzdulPXr18t73vMe2b59u/z7v/87/CVJRG7T398vX/ziF+Uv//IvZWBgQG644Qapq6uTQ4cOyfe+9z25++675bOf/azYti3//M//LB/60Ifk4osvlvXr10tHR4fs2bNHdu7cOf0H1sMPPyyrV6+WP/iDP5A777xzOlrY0NBwykz/bDZu3ChbtmyR6667Tnp6emR0dFQeffRR6e7unv7Esr+/X2KxmDz22GNSV1cnkUhE3v3ud8/680t33XWX3HPPPXLjjTfKNddcI1u3bpVnn332pE8N77//fvnOd74jN910k9xxxx2yYsUKmZiYkB/+8Ify2GOPybve9S51H5544glZvXq1LF26VNavXy9dXV0yPDwsmzdvlvr6evnRj34kIiIPPvigPPPMM7Jy5Ur51Kc+JZVKRTZt2iRLly6d9Z9sXeWM5Rhcbtu2bebWW281HR0dxufzmfb2dnPrrbea7du3z/i+E1GhU0WA3hwtNMaYbDZrPv3pT5umpiYTjUbNDTfcYPbu3WtExPzd3/3d9PehaOF111130nZWrVplVq1aNf3fhULBfOYznzEdHR0mFAqZyy+/3PzqV7866fsYLSQ30J7R7373u+aKK64wkUjERCIRc/7555tPf/rTZu/evTO+78UXXzTXXHONqaurM5FIxCxbtsxs2rRpxvf87Gc/M5dffrkJhUKmvr7efOhDHzK7du2a0768+Xl/7rnnzPXXX286OzuN3+83nZ2d5tZbbzX79u2b8bof/OAH5oILLjBer3fGs7xq1SqzdOnSU56ParVq/uIv/sLE43ETDofNtddeaw4cOHBStNAYYxKJhPmTP/kT09XVZfx+v+nu7ja33367GR8fn3UfjDHmlVdeMR/96EdNc3OzCQQCpqenx9x8883mueeem7GdF154waxYscL4/X6zaNEi89hjj52yf7qZZYzyG2zorPDqq6/KJZdcIt/85jfltttuO9O7Q0REv2P4MwNnmVMNLnrkkUfEtm258sorz8AeERHR7zr+zMBZ5stf/rK89NJL8t73vle8Xq88/fTT8vTTT8vdd98tCxYsONO7R0REv4P4zwRnmZ/+9Kfy4IMPyq5duySTycjChQtl7dq18rnPfa7mCYdERHR242KAiIjI5fgzA0RERC7HxQAREZHLcTFARETkcnP+ibKho0dgTZtcVevgmnKlAGvZ7Mm/fvKEXLai1EqwVqni7YmIRKJ4KMeh4XFYyxYTsDY6sRPWjo4MwJrfH4C1kA//nm7L/35YK5uDsFaYeBLWPPK/sJYp43NqjE+p4XumUoYl8XnDuCgihTwelOLx4v2xPfg3N5aK+BjLys7m3jRl7o2KJTxc5elvHYW131VHhpXeEVDuA613GHxNtN6RyeHekc8q1yuDe0d51t6B78uBo7X2Dvw7/Y8eHYA1n9Y7/Lh32D487rek9I5iUukdRukdlZMj0icYB98zjtY78B8N4vfovSNfwO/r8eD98XjxfVos4mMsl/G9mM/mYK2g9NxnvjUCayL8ZICIiMj1uBggIiJyOS4GiIiIXI6LASIiIpfjYoCIiMjl5pwmqBbxT2Jbyk9bW8pP/VqCa04F//Smrfxa3cGhQ7A2MnwM1gol/FPGr28U/zTxZA7/ZLil/JRqvoR/8rPimYS15thFsFbN4vkDVeWXTda1wJIYC//UazaFr5NjxWCtkk/h7VXwuRaDkyu5XBq/TkTSafxTuMFgBNdC+BpmlGRLVvmp31wOn9NqVfmx53nIKeHjsbz4ehoH/10Fdw4Rp6qlRnDvGDjyGqyNHD0Oa4XibL0Dp0Om8krvsPE9mVN+arzinYI1rXdUcrh3VNTegWvGVp6BpNI77BjelxzujVrvMIJ/6j+rpExERNJpfJ2CIXydQkpNS8VlM0rPPcUwuhNOp3fwkwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5eYcLTx+HA9IaWtthbWKMh3CKHGVvBIRyVdwdOjAwUFYy+VwzKXq4LiGiEihlII148ERkVIJDwbxBzywVl+nDGkp4ZrPUaI1BscuPQYfv88ThLViGV/fqhfHn2wPvva5rDL4xSjrVyWKJiJSreJzoyT9JBDEx6/N0sllcaSsqER16+qi+E3noWPHcO9ob22DtYoSk3IcpXdU8XkvKL3j4GuHYe10eke+mMRFL+4dRa13+JXeUY+P0Si9w1/Fw3FKXhy7rLV3FJRBXo4WV/fia1/IKtdCibmLwedTZLbegd83qPWOKn5dLofv4VIBPxfROhxlnA0/GSAiInI5LgaIiIhcjosBIiIil+NigIiIyOW4GCAiInI5LgaIiIhcbs7RwlR2BNbCRSUGYuGaFjssKbGLUhXvtseP1zfeKq6ZqpIRE5HJBJ6U1VjfAGshL44ktTbi/WnrwdESq3QQ1ipTv4G1kj+GawYfgy04ynO8MAFrTgBHnGwHR2ACfmXSlzJcrFRUph2KiG3j+JARZYKakh/0KO/p9SgT+Xx4gppl4dp8NKn0jojSO8TGtWoZ31ta7yg6+Hp5/Ph13gp+Vh0H74uIyOQ4niJYa+9oa8LHofeOA7BWmWyEtWIgBmta71ASxHI8j3tHNaA8c1U8RdQfUCY9ppU/U0r4nImI2B4teoivv9Y7bA++pzxK7/BrvcPGr5sNPxkgIiJyOS4GiIiIXI6LASIiIpfjYoCIiMjluBggIiJyOS4GiIiIXG7O0cLhib2wlioOwVoggCdvFYs4zlFVptMZC8cnKtZxWHOUKXqBsB4t6fTjOEtPSzesRaP4vJkCniLY340nvTWGR2GtPIljLqM5fN6OjSvxID/ez3ofvk4HE3iC2NFjOKpTUqaAZXFKS5KpNC6KSEsrngYYCOJHIZ3GGy0WtUgiPg4tjVYqKHmseWg4uQ/WUqVhWAsE8P1aKODn1VF6h6NEr8qCnyvHh+/loF+PtHb24t7RG8e9IxLdA2umgKcInqP0jlh4DNYqk/heHs3iONvIeAzWvC219Y4DE/h8jxzDryvlcC2bxs/VRHK23lEHa361d+D3LSiTS42SdNdS8OWCHpHX8JMBIiIil+NigIiIyOW4GCAiInI5LgaIiIhcjosBIiIil+NigIiIyOXmHC2cKuPI3lQSRzY8HryJcqWsbFGZ9qRMM/Ph9JhEcMpR/EE9HhQN42lY7fX7Ya2z82VY80zh81bvxVMSvUUcuzE2jlzZEby9hjCOP0VCSVgrFvC1KP8vjnEdPID3c2oKR27yGRxxSk9p95NIUzNe+xYK+LW5HI6kVqv4nBaU2GEhi1/nV+7T+WiyfAzX8OA68Xhx76iU8fNqLG3KpNI7cHpMoqfROyIh3JQ6GrTe8QqseabwMdZ5cRTWW8CTEI1Va+8IwVo4jHtHSekdJbV34POdVuKReu/AE3RFRJrieF8LBbw/eaV3VLTeocSLtd7hO43ewU8GiIiIXI6LASIiIpfjYoCIiMjluBggIiJyOS4GiIiIXI6LASIiIpebc7TQp0xmspQojyU4zmEpWy8WU7BmHByD8yvZQtuPp5J5/DgCIiLiERx3i3t/BWutgqeLiQdHcsopHPPJpbX4DM5qeerw2q+7HUcZS1Vc8/uDsBYL4GtfUYZrFZWRflWc8JFIPd4XEVGuoEhOiRZVKnijFSXGVTR4MqNtdcCaU9GjavONP6j0AOWqWJbWO3C8qlhIwZqj9Q6v0jt8uHfYvll6h6X0Dg/uHS1a77Bx76gk8f2Tyyhx1xp7R1d7CtZKFdw7Aj6ld/jxta8qTaBotN6B75log57Jc5RBotm00jvKtfYO/IejbbXD2un0Dn4yQERE5HJcDBAREbkcFwNEREQux8UAERGRy3ExQERE5HJcDBAREbncnKOFIjgi4fHgmnGUSKKtTBfz4mhdqZBR3hNvz1fFk7AqeBDg69us4shGJIQjIr5xfG6SE3iCWHJUiU5l8TEmkjjmFI3hqFvIg9eFRaNERwM4ytPT0Yy358f7MqpMAXOq+L5wLH3yWLGKL3KhhK+FZeHYUSSGz1ulqtzfZRyd8vjTsHa28Xjx+XPU3oHvO68X3z+lotI7lKyz7eDeodxWr28zgydiRoL4WvvGlN6RxPdrCg+YlUIWP3cTNfaOoNY7lEyeHaytdwQDeF9Ko1rv0CZd6r2j4OBzUygqvcPWegc+jmoVnxu7jO9Frx/f37PhJwNEREQux8UAERGRy3ExQERE5HJcDBAREbkcFwNEREQux8UAERGRy805Wujx4BiEWDg64zhKFMzBcQ6ftw7WKhaOclQF1wJOBNZaGmFJRETa6obw/qTx8Q+P4fXW+Cg+/QMH8HFMJnHsJFfCUZ6mOI6zlQs4AuMNKtMOz8Hn1FKmi00O4zxWaRLfa8aDj8/x6NPjJiezsNZQr0TcKkqsLIcnr5Wz+N63nTFY8/pwVHU+8ihxX7HwfaDFSI3Bz5xXmT5YUSKkVaWv2FX8nnGcghMRkba6Ybw/GRx303pHYqy23pFK4p6bw6dbmpXeUVJ6hy+k9I5+fE4tB79uaqjG3uHFUV/Hrr13xLTeocQAnTzuHaUs3p+geXt6Bz8ZICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFyOiwEiIiKXm/PvGbCUdYOjZH6N4Fy4EWVMo4RgzefFWdKig/OgfrsJ1iK2MvdTRNobD8KaM4lzr8dG8HnbvxdnSZMT+NJUqzjzazw4R5yaxLVdW3E2Od6Kf19AWzeuVcspWIv68DnLB3E2N9KMr+GUHhWW5hac6w2F8D08dgyf73Qa39/eKr6GHXF8D3cuaoC1+ciy8D2i/a4RjaP0Dr+EYc2r9I5SFT8D/gC+J6P2MVgTEWlvPABrZgo/B8e13rEP3+ypBL5fK0rvEA9+BlJT+Hzv2oZ7bs29o5SEtYgfH3ud1jviuHek83hfRESaWvDvUgirvQPvj9Y7fFV8n3bElb7SXw9rs+EnA0RERC7HxQAREZHLcTFARETkclwMEBERuRwXA0RERC7HxQAREZHLzTla6PPjiESpiuNBtkeJjzg4riI2jvl4gjjK4ikr76mMU5ZMBtdExErhbRaVEcajx/D+TCRwtEQsHI+yfTh2UrVxVMkYfC0KBWW0qXJqppL4vITq8Hn50Go8ovpwAtdGJnHkdFgZCS0iEvbj1xayKVibSuLjyOXxWNSAha9vazOOKl21Ekeg5iOfDx9rSYkWWsr9apXx64xXGW8cVEYYK73DOHjUsJm1d+BtFqa03oHvrWRC2yLuHR4/7h0VC2/POPhaFEtK70jj100l8XkL1eH3/PAHlN4xgccij6Tw8z80hs+LiEhE6R357CSsTaWU3pHD59uv9I6WZryvp9M7+MkAERGRy3ExQERE5HJcDBAREbkcFwNEREQux8UAERGRy3ExQERE5HJzjhZ6bBxnmExO4NdZOFZUqeDYid+Dt2cMfs9MDsd4QuEhWAvXHYU1ERGjRAvT4zgiokULJ5NKdMqHoyW5Ko4Plqs4PhmL4IllUR++FQp5HKtKTeDtNeOUj1xyAY6qmoP42IcSylRKr7JBEUkl8LSzQg5fp0oZx4N6F+FJiFYZ76tlcBypMYzvp/lI6x2pWntHFT87AVubsIrfM5tTYrJK74jUjcCaiIhJ4Qjd1Di+10ePKxNIld5he5Xe4eD+WK7i5zwWxr0j4sc1rXckJ3AtHsHHcLHaO2BJjmi9wzNL71D6XD6Le0dZ6R09Su+wK1rvwO/ZGFbi6rPgJwNEREQux8UAERGRy3ExQERE5HJcDBAREbkcFwNEREQux8UAERGRy805WmgJjjtl0niEVqWMIzCVCt6818Y1U8VTqzI5HAEJtR5TtocjTiIipSSOj+RSeE01qUwXK+TwJCzjw/GZVAHHgypVHC0pKREYfwuOBwVxGkuykzg2VpfG7yk2jseUpvA9kxzHcauiwdPaRESyaXzeLOVRWPF7PbB22Uplg6VRWMqM4OhQ0ML7OS8p0/AyGa134LfUeofPxvedU8G9I5vH0dNgy3FY89rqCEEppfDx51PKVD+1dyj3ug8ffyqvRAsdvJ+lDH7uulvx9qoBJeao9I5iI35P48GRxFIaltTeUTK4F4uIZKbwebMtpXeswL3j3Vfi7ZkSvt+yI0p8XnBfmQ0/GSAiInI5LgaIiIhcjosBIiIil+NigIiIyOW4GCAiInI5LgaIiIhcbs7Rwp44jqVFbJw9GxjGE712KxOmPN4YrPn9OFri2DiSly3h/RwcwTEXEZGSg6Mu2TKeIljBSUcpFfA2K8oyzWg1ZeBdroRjTEUlqlVQIl6ZPN5gsYKvxfYdOObzwm9wHGnwOD74+g7lZItIY3MDrHUv6IO1vn4lAlraA2ut9fjELY7haJjJJWFtPuppxtda6x2DQ7h37KqxdwS03mFpvQPXBo/pbbTDwfVMRZlAqvYO/BxUtf7gwc+WMbg/qL2jjHujv4zjmpkc3pfGstI7tuM/i7b8Bl/fweP4GOo78etERJqa62GtayHuHYsW1dY7WurwM3Nug9I7lHjsbPjJABERkctxMUBERORyXAwQERG5HBcDRERELsfFABERkctxMUBERORyc44WdscPw9rCeAbWfHYK1vYP4LXIeBJHS+JxHEcKN+DXWf4mWBvLp2BNRCTSgPfVCeHIit+HX1cs4hiICeNLE/TjuEpeifLYPnzeSkp80BfCx1DXjF/nieLakJKe2/cajg5lHHx9q5EUflMRyfqVmNMhvM1oCz5vCxbge98vY7AWUB69iWHlYsxDNfcOC98k+wZxLDeRUnpHM76WoRiOyFl+fKOP5iZhTUQkHMP7aoK4dwR8ylS/gpI7DOF7K+BTom5K77B8QVgrVXBE0Kv2DnzsdhTXhpJ4e3rvwMfuTKZgTUQkF8DHn34N51zrlD+rumvsHX6ldyRPo3fwkwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5eYcLXTMr2At4BuHtc52HAOJBHF0ZuvQBKzlijjm0W51wJpdjcFaXw+uiYg0tuCpVvkCjkA1xrOwZo7gWnoKx05i4Qishe06vD2DJ2FVCzlY89r4GoaU6JDlxVGlJRfimOf2/XgS4sAorhWqOFYkIlJRUjcTY/ge7pnEkbNOZSpZg+B9zexXrv0xHKuajxzzP7AW8OEIVZfSO6IBrXckYC1XwNer3VZ6RwRPvFy0ENdERJpa25T9qa13iNY70vi8xcI47xuy8X2u9Y5KHk9e9Cq3ckiJZNtK77jgwkZY27EfH/uhMfw85mfpHWWldyQyuHf0TtXWO2IW3tf029Q7+MkAERGRy3ExQERE5HJcDBAREbkcFwNEREQux8UAERGRy3ExQERE5HJzjhZazhFYq+ZxDKQhiGM3zcpkqnIexydSSRxzsbw4qlSK4nxINTsFayIi+W4cn4lO4vf1N+JIYrwbb29sEE8lSyTw8ccC+JKGleNva1OmJAbxFLipNI7AVKM4/jV6HB9DJouP3a/EKu0QjlWKiOSLeF9LBtcOD+D3fOEn+BhXLIrBWmsFH2M+iWOe85Fl8NTCah6fh4ZgPaw11eG/x1Ty+PwlkzhCpvWOYhQ/x9XMLL0jjXtHJIWfA38jfl6bld4xOoj3tTKegrVYEPeAiNI72ttwfC4Uwr1jMo2vRUW5vsdH8TlL52rrHZ7T6B1lJUI8OICjjlt+invH8kX4z02td+ROo3fwkwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5eYcLcwrcY6sMlzLE8Gxk3O7FsBaYwRvbziB4xM+H45y2GVcq+b1aU/BIK4vDODX1SnTDjtsHC3J+HEkpziOIzkNARwBiitT4Jpb8fFZHhzJGU/j9eSeBI7AbN2DpzI6No6UBYI4ApTOp2BNRCRfxBEvU8bXYnw4DGu/fhHf/PVlfO3be5phLatEruaj/HF8PFklCeUNK72jE2frYhH8DAwn8D3g9yu9A7cjcWbrHcp0vp4A3qbWOzqV3pH14/NWVCb31QeV3tGG97NJ6R22Fz87iTQ+hr07tN6hTIK1lN4Rxr0jMWvvwPF5U8Y9cHwY906td9QpYxLbF8ZhLTs1Cmuz4ScDRERELsfFABERkctxMUBERORyXAwQERG5HBcDRERELsfFABERkcvNOVp4bBeOlpRTOCLiiylRljjefH0Y1/YeUabvCY7VVCv4PSuWPrWqEojiWt0kfmEIR1LsKj5vLQubYC3YgY8/5EnjWgxHvOwArk0kYUmMvxPWGjuDsHauEh2dyOHrtPM1HJ3JK1FGEZGCMl1TcjgferycgrWeBTj+1bsUv2c+hWNFySklxzYPHdutTHxL1to78HPeEMK1vcqEwXaDX1ep4P0sK9MVRUSqAdxbymrvwPezVcV/j4trvaNd6R3eGnuHH9eSSRw7dEK19Y7FYfx8JGvsHbkEfo5FRIo5JVqo9I6C0jt6u5XecYHynpPKRN/T6B38ZICIiMjluBggIiJyOS4GiIiIXI6LASIiIpfjYoCIiMjluBggIiJyuTlHC4/swtGa4hh+m2oETwlbePkErLW34+11ZvDEt+Y4nhJVreCYi5IqEhERfBQiWQtP5gp4cCSxZIfwm/pbYcn2HYc1rx/vS1mJAFlRHHMJBvG+SB2eHudvxTGmBZ34jEbS+HWDk3g/nSM4iiYiUkrjeKyTxjGuoBdfp2IW3/vHxnAcqZrB4/pyOf045psjO/E5Ko3h51zvHQlYa+uorXc0teDe4VTw35uM8lyJzNY78L0VtHHvKCuvs3wtsObx4t7hCyi9w1db7wiElN4RVXpHG37PhZ34uYpm8OsGp5TeMaRfw2IGP5NmCu/P29I7lDHBuTzucbPhJwNEREQux8UAERGRy3ExQERE5HJcDBAREbkcFwNEREQux8UAERGRy805WpgYwZGFqpKdSWVwRCKcSsHa+cvaYW1cWcL4fDgCks/hSIbHj99TRCRXwLHEgQyOpSWVzGLEacO1aA+s+Qw+Rn9Y2Zd8CtYKSrLGF8XxmLyNz0smi6+9zz6Ga148eau3G0+AG9qnR/KyE8rEtii+TtEAvuGalIF1QYPPTb6oRIfs2uNBv4sSI/i6OHncgpJZ3FhCKTztb8lF+Lkax5dE/FrvyGdgzetX3lRElIF3MqhE4ZIGn5tIFUf2InW4d3gdfIy+iLIveTy6tFDFx++P4OmDOZwAlazy54bPMwJrXi9uZL3dOKp5ZJ8eLcwpvcNXh3tHndI7Ghvw9kLK9N18Ee9r1a49lsxPBoiIiFyOiwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFyOiwEiIiKXm3O0MJ/D8ZFgPc7lVSo4kjGhTJETnCATy4/jExUHx9KCIbz28Xn0UxGo4Hid38bxGcsKwJpHcDwoHMDT1WyD44OOPwVr1TKODk3m8BQ9y0nDWsWegjVPAV/foODrVCzh2FhPyyWwVnf1ZbAmIjI4PAhrHh++v5vq8PFfcv4wrHXHcTRubArfT9GOOT+W80I+h5+7UD2OUFWqSuwwrUyRU+KettI7ygbfk4EQzsH5PEpGTkQCZTwN0O/B/cEW3Fc8HiVaGGzC7+ng3mGU3uGU8eum8krvMPjZKau9A5bU3lFSesfCluWwtnqW3nF4+DCseby4dzTWa71jCNa64/gEjE7i+ynaXnvv4CcDRERELsfFABERkctxMUBERORyXAwQERG5HBcDRERELsfFABERkcvNOYfgCI4PFsq4ViorMcASnkw4MoBjcFNJHGWJ+CKwZjt4PxsbO2BNRKSjoRPWomEcA/QYHDuqZHHNquB1mrFwdGgyjaOc40kc47IieKKX5cH74vhwfC6nTJ1LZHDN78WRqqBS627B0+pERDpa8JiwVAFPQmttwVGe5kZlSmQKR4dKDr72nefj52I+Mha+7wplHK0rVXA0tVzGz+uxQ0qEVukdUaV3eNTegXuDiEhnDO9rNBSHNVv5u1o1o8QZq8rzauPekUrjyN7YhNI7ojgHbtk19g6lP0woNZ/aO/C9tmCW3tEZV3pHEfeOljjuHfEm3DsmkkdgraxMs+w8Xz8ODT8ZICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFxuztHCrDKBrlTAUY9qGEdy4i39sJYv4GlPsVwC1lqiXbDWXrcQ1jobu2FNRMRv4SlzThnHfEoVPH3Ko5z+fAm/Lq1M9Np/IANrBwdwrWsxvk6d/ThW4/XhY69KFdYcP444Fcs4xjQ8hI9hYTwLayIizTFlnF0Qx6OqRXwc+SyOjTllHPMse8fw68L4/p6PMsr9Ws4rvSOi9I74IlgrFHHvaMzjcxtXe0cPrHU24teJiPgtHC8zJfz3sWJFmU5qKb2jiM+p2jsO4vOm9o5z8PPaeY7SO/xK77CU3hGorXcMDeH+MGvvaMC9wyi9w1F7B44QaxNm1d4Rqb138JMBIiIil+NigIiIyOW4GCAiInI5LgaIiIhcjosBIiIil+NigIiIyOXmHC0sVnBEwgrhyYSBBhwP8tXh6Ex3vBXW4m1LYC1stcBayGmENUuJ+IiImJIyfbGi1Ko4knlkCE+127PvAKxFmnA+aGgE78vWbThytHsQR1J6juCYywWX4EhmUweO3JQcvJ9HB6dgLX10AtayswzsOnchjrJGW3FcyevBtUoJR5IsLz5GiYzDUjWLo0PzUams9Q5cC9Tj3uGvx72jy19b7wgJ7h1hpXeIEi0WERElXlZWJjNWlGdk6AjuHbvV3oF7wNAI3pdXt+LX7RrEz6TWO5YuXwBrau+o1tg7hpXeMcug0PMW4ihrROkdPqV3lIu4d9g+fIxGiR5Xc7ivzIafDBAREbkcFwNEREQux8UAERGRy3ExQERE5HJcDBAREbkcFwNEREQux8UAERGRy8359wzkqjgv6rMtWOtQMpglwWMxfTbO/HqcGKxZlQCslZV8qtfGWWARkaLB+5qr5GBtNDEMa/+7czusDQyMwtq5S/HY3GwZH2MZXyaxBWel9+zG2VV/OAJry1uU8K5VgaVoGB/fcHI/rO0Y3YG3JyJjA0lYa2rFmeeG9hisNXfgR6gxrvyOjQAeaxsI4mdtPspW8e8E8Nv47yPtbUFY03qH38a/Z0DvHXh72u8D8Nh4VLWI3jvySu84XmPvGFR6x2Kld+RKyu9DsHDz8Bh8Dffswb0joPSOS2rsHRGtd6Tw71/YMYbPp4jI+KHffu9oUnpHUwvuHd5ACNaCgdp7Bz8ZICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5bgYICIicjkuBoiIiFxuztHCUAxH1qJNeNxkXUMzrCUncJTH68FRltYwjmXZHhxXmcrhiI/48ThJERETSONaEEenGiL4vPWV8FjUyRLenuPB8ZGmDhytXNl+Hqy1dUVhLZ3BI5NtZUyvx4Pjil4Hx4P6evC40LYQjhz9v58/D2siIgcO4rGv9eP4+neWcFRtqoTP2/A4jiOdv7gT1uxAHNbmo3AjjuVFG/GzXK/1jgTuHR6lq7UpvcNSekdaeR7NrL0D9x0TxM+W1jsWlWvrHcaLe0ej0juu7DgX1lqV3pFReoc24ttj497h8Sq9Qxk13K70jl9v1nvH/oNHYK1+HF/fzrLSO8pa70jB2pJzce/w+GvvHfxkgIiIyOW4GCAiInI5LgaIiIhcjosBIiIil+NigIiIyOW4GCAiInK5OUcLz7kYR3J8vm5ci54Da06wF9YsB8cuJifysDaSGIS1dCUFax299bAmIhKJ4ahjRXB8xvHifV28DEdd4sq0q+TEGKyF6nEcK1iPJ0h6A8rEshKOhvn9PlirGBytOzxwDNb2DO6DNV8eb892cDRKRCSdwftj+XGtfQGOZHb24ollR0bwcWQyeF8DIfyszUf9b0PvMErvkCqOCKYm8LM6Mn4Y1jKn0TvCjUrvMLX1jnMuwr2juS0Ga8kknmgYrsO9I9CAe4fvHe4dg0rv2Kv0Dq/SOzxmlt6Rxftj19g7unoXwtrho3vxvqTxvvpbau8d/GSAiIjI5bgYICIicjkuBoiIiFyOiwEiIiKX42KAiIjI5bgYICIicrk5RwvruhtgzSngeFWlhCcsTR7DkZux0aOwdnj4NVibMjh20tqHI0D+LI7OiIgULRx1DEZw1MPj88NaxeRgzQpNwVqgoQxrkQYcLfFH8DHkijgeIx48JaxUxhMbfZ4QrNlVfC0G9u6GtcRrKbw9o9/OthfXTQCvi48llFhREJ/v1pYuWPMG8PS4so2fi/moXu0dOFpYVnrHFH7MZVTpHUdq7R29+Bj8OTxBUESkYOGprqEo7h22F/eOquDeYSu9I1jFz7LWO3wRfAz50gSsGbu23uG1ce/wKL3j0B7cOyYOTeLtOXhKooiIx4NjiU4Qv/a4Mn1Q6x1trVrvwP2/chq9g58MEBERuRwXA0RERC7HxQAREZHLcTFARETkclwMEBERuRwXA0RERC4352ihY+KwNoqH6MnwETwJbHgIRz3GEylYS2bGYS3Wg9c3DQ6Oh6TzaVgTEQkr0Rrbxu9byOMIUKWMp5KVijiSYykROq8dhLVIAEegqmVl8lgVH0O5jGvFPJ7IFgjjSJXlx/tifDhWUyjhcyYiEo3hKI8VwNdw5y4cR9u7D9/fSy/qh7WLlvXAWi6PI1fzkePgaXijozgKNaT1jmGldyhxrmQGN6tYD46INTg45jeVw/eOiEg4jHuHZeHXFpXeUa7g3lFWeodovUOJAkcCMVhzKkp8UOkdFa13VGrrHbYyQdF4ce8onkbvsJXpi1rv2KP2jkWwdtGyXljLKT13NvxkgIiIyOW4GCAiInI5LgaIiIhcjosBIiIil+NigIiIyOW4GCAiInK5OUcLd23DkYW9O/fDWmIcbyKTxZPbCiW8vXRBmcrVEYO1cF0E1upieCqZiEhEea2xHFjLZpVoTVGJwZTxeculcfTMKeGIZD6TgLXhoRFYq1emmcXiODY1MIIniIUiOKp1we/hSXbjbXjy4vFhPD1NRKR7AZ4E1hzHtbGxFKwdUeJvQ0eHYK29KwZrntzZFS3ctQ0fj9Y7xpXekc3i98yXcC1TxL0j1Il7QEh5/usb9d4RrsevFRv3jozSO6pq78ARyWxaex0+N7k0fraODtfWOxre4d4xpvSO0Vl6R1c37g9xZTrp6GgK1oaGauwd3Tgi7mW0kIiIiGrFxQAREZHLcTFARETkclwMEBERuRwXA0RERC7HxQAREZHLzTla+D8vHoe1yUk8RSpfwOuNfBHHIByDp0iVLVyL1uP4SHNLC36dEh0SEbG9OK6TUyYe5pWoh6OkQA7vPwZrydEMrHX14Alak2n8njtf3QdrvX0LYG3hBa2wdjQxCmvxVjxdMRDCt+WCC/D0zAsvPRfWRER8No4k+Tw4AtXTj++bJcs6YK1cwRG3ahVPnTs6dBTW5qP/+SW+71KT+D7IF/BEw3wRn1vj4Ol0JRv3jkgdjro1t+L7Tosdi4h4lN6RzadgLV/A94hResfgftyrk8dxr+rqVXrHlNI7tiq9oxf3jh6ldwwrvaOlxt6xcInWO86DNRERvzJd0ufF13+h0jsuyHXCWknpHY4yCfLwafQOfjJARETkclwMEBERuRwXA0RERC7HxQAREZHLcTFARETkclwMEBERuZxljDFneieIiIjozOEnA0RERC7HxQAREZHLcTFARETkclwMEBERuRwXA0RERC7HxQAREZHLcTFARETkclwMEBERuRwXA0RERC73/wGxnuSZmO7M6QAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reconstructed_val=torch.tensor(sol).reshape(3,32,32)\n",
        "oringinal_val=torch.tensor(org_x).reshape(3,32,32)\n",
        "plt.subplot(1, 2,  1)\n",
        "plt.imshow(tt(oringinal_val))\n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2,  2)\n",
        "plt.imshow(tt(reconstructed_val))\n",
        "plt.title(\"reconstructed\")\n",
        "plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Error in the construction(MSE): 2.2904629919850007e-22\n",
            "PSNR:  264.53157081785514\n"
          ]
        }
      ],
      "source": [
        "#measure the quality of the image\n",
        "\n",
        "mse=mean_squared_error(np.array(oringinal_val),np.array(reconstructed_val))\n",
        "print(f'The Error in the construction(MSE): {mse}')\n",
        "\n",
        "Max=255\n",
        "PSNR = 20*np.log10(Max)-10*np.log10(mse)\n",
        "print(\"PSNR: \",PSNR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
