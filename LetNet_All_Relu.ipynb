{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWa7Xo6PkIl3",
        "outputId": "e150aaca-6a7e-456b-e100-e3cd2040e766"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from pprint import pprint\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import grad\n",
        "import torchvision\n",
        "from torchvision import models, datasets, transforms\n",
        "import torchvision.transforms as T\n",
        "from skimage.metrics import mean_squared_error, structural_similarity\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "torch.manual_seed(50)\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjKWqs2akepH",
        "outputId": "248e5f68-6414-4e11-8ad1-37e2df07469d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "dst = datasets.CIFAR100(\"~/.torch\", download=True)\n",
        "tp = transforms.Compose([\n",
        "    transforms.Resize(32),\n",
        "    transforms.CenterCrop(32),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "tt = transforms.ToPILImage()\n",
        "\n",
        "device = \"cpu\"\n",
        "# if torch.cuda.is_available():\n",
        "#     device = \"cuda\"\n",
        "# print(\"Running on %s\" % device)\n",
        "\n",
        "def label_to_onehot(target, num_classes=100):\n",
        "    target = torch.unsqueeze(target, 1)\n",
        "    onehot_target = torch.zeros(target.size(0), num_classes, device=target.device)\n",
        "    onehot_target.scatter_(1, target, 1)\n",
        "    return onehot_target\n",
        "\n",
        "def cross_entropy_for_onehot(pred, target):\n",
        "    return torch.mean(torch.sum(- target * F.log_softmax(pred, dim=-1), 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "AorI020iVjjS"
      },
      "outputs": [],
      "source": [
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-.5, .5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        act_relu=nn.ReLU\n",
        "        act = nn.LeakyReLU(negative_slope=0.2)\n",
        "        self.body = nn.Sequential(\n",
        "        nn.Conv2d(3, 77, kernel_size=5, padding=5//2, stride=2,padding_mode='zeros'),\n",
        "        act_relu(),  \n",
        "        nn.Conv2d(77, 22, kernel_size=5,padding=5//2, stride=2,padding_mode='zeros'),\n",
        "        act_relu(),\n",
        "        nn.Conv2d(22, 3, kernel_size=5, padding=5//2, stride=1,padding_mode='zeros'),\n",
        "        act_relu(),\n",
        "        nn.Conv2d(3, 3, kernel_size=5, padding=5//2, stride=1,padding_mode='zeros'),\n",
        "        act_relu(),\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(192, 100)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.body(x)\n",
        "        out=out.view(out.size(0),-1)\n",
        "        out=self.fc(out)\n",
        "        return out,x\n",
        "net = LeNet().to(device)\n",
        "net.apply(weights_init)\n",
        "criterion = cross_entropy_for_onehot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "8mSgR4GClV-8",
        "outputId": "abe34e49-905b-4d53-f8cb-d7cf1347e9b1"
      },
      "outputs": [],
      "source": [
        "######### Feed the image to the network and compute gradients #########\n",
        "img_index = 2\n",
        "gt_data = tp(dst[img_index][0]).to(device)\n",
        "gt_data = gt_data.view(1, *gt_data.size())\n",
        "gt_label = torch.Tensor([dst[img_index][1]]).long().to(device)\n",
        "gt_label = gt_label.view(1, )\n",
        "gt_onehot_label = label_to_onehot(gt_label, num_classes=100)\n",
        "\n",
        "\n",
        "out,org_x = net(gt_data)\n",
        "y = criterion(out, gt_onehot_label)\n",
        "\n",
        "dy_dx = torch.autograd.grad(y, net.parameters())\n",
        "\n",
        "# Extract the gradients and initial parameters\n",
        "original_dy_dx = [_.numpy() for _ in dy_dx]\n",
        "param = [i.detach().numpy() for i in net.parameters() if i.requires_grad]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to return the details of the layers (e.g., input dimensions, number of filters, padding, stride) for use at runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inspect_model(model,x_dim=32):\n",
        "    conv_layers = []\n",
        "    fc_layers = []\n",
        "    parmeter_index=0   # Hold the index of the parameters of each layer\n",
        "    input_dim=x_dim\n",
        "    input_dim_fc=0\n",
        "    act_fun=''\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            output_dim=int((input_dim+2*module.padding[0]-module.kernel_size[0])/module.stride[0])+1\n",
        "            layer_details = {\n",
        "                'param_index':parmeter_index,\n",
        "                'input_channel': module.in_channels,\n",
        "                'number_filters': module.out_channels,\n",
        "                'stride': module.stride[0],\n",
        "                'padding': module.padding[0],\n",
        "                'kernel': module.kernel_size[0],\n",
        "                'input_dim':input_dim,\n",
        "                'output_dim':output_dim,\n",
        "                'act_fun':act_fun\n",
        "            }\n",
        "            conv_layers.append(layer_details)\n",
        "            input_dim=output_dim\n",
        "            input_dim_fc=input_dim**2*module.out_channels\n",
        "            parmeter_index+=2\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            layer_fc_details = {\n",
        "                'param_index':parmeter_index,\n",
        "                'input_dim':(input_dim_fc),\n",
        "                'output_dim':module.out_features\n",
        "            }\n",
        "            fc_layers.append(layer_fc_details)\n",
        "            input_dim_fc=module.out_features\n",
        "            parmeter_index+=2\n",
        "        elif isinstance(module, (nn.ReLU, nn.LeakyReLU, nn.Sigmoid, nn.Tanh)):\n",
        "            act_fun=str(module.__class__).split(\".\")[-1].split(\"'\")[0]\n",
        "            conv_layers[-1]['act_fun']=act_fun\n",
        "    return conv_layers,fc_layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to compute the gradient w.r.t the input of the convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {},
      "outputs": [],
      "source": [
        "def drive_gradient(input_shape,weights,output_gradients,stride,padding):\n",
        "    weights = torch.tensor(weights, requires_grad=True)\n",
        "    input_tensor = torch.randn(input_shape, requires_grad=True)\n",
        "    dL_dY = output_gradients\n",
        "    \n",
        "    # dummy forward pass to build the computational graph\n",
        "    output = F.conv2d(input_tensor, weights, stride=stride, padding=padding)\n",
        "    output.backward(dL_dY)\n",
        "    dL_dX= input_tensor.grad\n",
        "    return dL_dX\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to reconstruct the input of a convolutional layer using gradient constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {},
      "outputs": [],
      "source": [
        "def construt_input_using_gradients(num_f,num_c,dim_x,output_gradient,weight_gradeint,padding,stride,kernal=5):\n",
        "    input_matrix=dim_x*dim_x\n",
        "    pad_dim=dim_x+2*padding\n",
        "    a=np.array(output_gradient)\n",
        "    Filters_gradients=np.array(weight_gradeint).reshape(num_f,num_c,kernal,kernal)\n",
        "    x=[]\n",
        "    indices=[]\n",
        "    for n in range(num_c):\n",
        "        cord_a=[]\n",
        "        cord_b=[]\n",
        "        rank=0\n",
        "        for i in range(num_f):\n",
        "            for k in range(kernal):\n",
        "                for l in range(kernal):\n",
        "                    if(rank==input_matrix):\n",
        "                        break\n",
        "                    cord_b.append(Filters_gradients[i][n][k][l])\n",
        "                    array_gradients=np.zeros(pad_dim**2).reshape(pad_dim,pad_dim)\n",
        "                    array_gradients[k:k+dim_x:stride,l:l+dim_x:stride]=a[i:i+1]\n",
        "                    cord_a.append(array_gradients[padding:padding+dim_x,padding:padding+dim_x].reshape(input_matrix))\n",
        "                    if n==0 :\n",
        "                        current_rank=np.linalg.matrix_rank(cord_a)\n",
        "                        if (current_rank==rank):\n",
        "                            indices.append(i*25+k*5+l)\n",
        "                            cord_a=cord_a[:-1]\n",
        "                            cord_b=cord_b[:-1]\n",
        "                        rank=current_rank\n",
        "        if n!=0:\n",
        "            cord_a=np.delete(cord_a,indices,axis=0)\n",
        "            cord_b=np.delete(cord_b,indices,axis=0)\n",
        "            cord_a=cord_a[0:input_matrix]\n",
        "            cord_b=cord_b[0:input_matrix]   \n",
        "        sol=np.linalg.solve(cord_a,cord_b)\n",
        "        sol2=sol.reshape(dim_x,dim_x)\n",
        "        x.append(sol2)\n",
        "    x=np.array(x).reshape(num_c,dim_x,dim_x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Function to reconstruct the input of a convolutional layer using weight constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "def construt_input_using_weights(num_filters,num_c,dim_x,Y,W,pad,stride,kernal=5):\n",
        "    a=[]\n",
        "    b=[]\n",
        "    dim=dim_x**2\n",
        "    pdim=dim_x+pad\n",
        "    for n in range(num_filters):\n",
        "        q=0\n",
        "        for k in range(0,dim_x,stride):\n",
        "            v=0\n",
        "            for l in range(0,dim_x,stride):\n",
        "                a_row=np.zeros(dim_x**2*num_c)\n",
        "                for c in range(num_c):\n",
        "                    x1_=np.zeros((dim_x+2*pad)**2).reshape(dim_x+2*pad,dim_x+2*pad)\n",
        "                    x1_[k:k+kernal,l:l+kernal]=W[n][c]\n",
        "                    a_row[c*dim:dim+c*dim]=x1_[pad:pdim,pad:pdim].reshape(dim)\n",
        "                a.append(a_row)\n",
        "                b.append(Y[n][q][v])\n",
        "                v+=1\n",
        "            q+=1\n",
        "    sol=np.linalg.solve(a[:dim_x**2*num_c],b[:dim_x**2*num_c]).reshape(num_c,dim_x,dim_x)\n",
        "    return sol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct the input and the gradient w.r.t the input of the first fully connected layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {},
      "outputs": [],
      "source": [
        "cnn_layers,fc_layers=inspect_model(net)\n",
        "FC=fc_layers[0]\n",
        "in_dim=FC['input_dim']\n",
        "out_dim=FC['output_dim']\n",
        "w_index=FC['param_index']\n",
        "b_index=w_index+1\n",
        "#Compute The gradient w.r.t input to FC sum ( bias * weight)\n",
        "\n",
        "FC_input_gradient=np.zeros(in_dim)\n",
        "FC_input_values=np.zeros(in_dim)\n",
        "for i in range(out_dim):\n",
        "    for n in range(in_dim):\n",
        "      FC_input_gradient[n]+= original_dy_dx[b_index][i]*param[w_index][i][n]\n",
        "      \n",
        "# Compute the values of the input of FC ( weigh/bias)\n",
        "\n",
        "for n in range(in_dim):\n",
        "  for k in range(out_dim):\n",
        "    if original_dy_dx[b_index][k]!=0:\n",
        "      FC_input_values[n]= original_dy_dx[w_index][k][n]/original_dy_dx[b_index][k]\n",
        "\n",
        "Computed_gradients= FC_input_gradient.copy()\n",
        "Computed_values=FC_input_values.copy()\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reconstruct the input and compute the gradient with respect to the input of the convolutional layers:<br>\n",
        "For each layer :<br>\n",
        "    1- Propagating the precomputed gradient of the subsequent layer through the activation function<br>\n",
        "    2- Constructing the input based on gradient constraints<br>\n",
        "    3-Computing the gradient with respect to the input<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "UE93IXSq41tt",
        "outputId": "3811071d-3de3-4ef4-f488-088890a5c2c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ta18336\\AppData\\Local\\Temp\\ipykernel_28192\\1859967760.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output_gradient=torch.tensor(output_gradient).reshape(num_filters,out_dim,out_dim)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "1\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for n in range(len(cnn_layers)-1,-1,-1):\n",
        "  # Extract the layer setting \n",
        "  cnn=cnn_layers[n]\n",
        "  num_filters=cnn['number_filters']\n",
        "  num_c=cnn['input_channel']\n",
        "  dim_x=cnn['input_dim']\n",
        "  w_index=cnn['param_index']\n",
        "  weight_gradient=original_dy_dx[w_index]\n",
        "  output_gradient= Computed_gradients\n",
        "  padding=cnn['padding']\n",
        "  stride=cnn['stride']\n",
        "  out_dim=cnn['output_dim']\n",
        "  act_fun=cnn['act_fun']\n",
        "  # Propagate the gradient through the activation Funciton\n",
        "  Computed_values=Computed_values.reshape(out_dim**2*num_filters)\n",
        "  output_gradient=output_gradient.reshape(out_dim**2*num_filters)\n",
        "  output_values=Computed_values.reshape(out_dim**2*num_filters)\n",
        "  for i in range(out_dim**2*num_filters):\n",
        "    if(act_fun=='ReLU'):\n",
        "      if np.round(Computed_values[i],7)<=0:\n",
        "        output_gradient[i]=0\n",
        "    elif(act_fun=='LeakyReLU'):\n",
        "      if np.round(Computed_values[i],7)<0:\n",
        "        output_gradient[i]=output_gradient[i]*0.2\n",
        "        output_values[i]=output_values[i]/0.2\n",
        "  \n",
        "       \n",
        "  output_gradient=torch.tensor(output_gradient).reshape(num_filters,out_dim,out_dim)\n",
        "\n",
        "  # construct the output_values of the layer\n",
        "  print(n)\n",
        "  x=construt_input_using_gradients(num_filters,num_c,dim_x,output_gradient,weight_gradient,padding,stride)\n",
        "  # Compute the gradient w.r.t input of the layer\n",
        "  dL_dX_CNN= drive_gradient(x.shape,param[w_index],output_gradient,stride,padding)\n",
        "\n",
        "  Computed_gradients= dL_dX_CNN\n",
        "  Computed_values=x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "View Reconstructed Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ta18336\\AppData\\Local\\Temp\\ipykernel_28192\\2635264957.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  oringinal_val=torch.tensor(org_x).reshape(3,32,32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(-0.5, 31.5, 31.5, -0.5)"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "reconstructed_val=torch.tensor(x).reshape(3,32,32)\n",
        "oringinal_val=torch.tensor(org_x).reshape(3,32,32)\n",
        "plt.subplot(1, 2,  1)\n",
        "plt.imshow(tt(oringinal_val)) \n",
        "plt.title(\"Original\")\n",
        "plt.axis('off')\n",
        "plt.subplot(1, 2,  2)\n",
        "plt.imshow(tt(reconstructed_val))\n",
        "plt.title(\"reconstructed\")\n",
        "plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Error in the construction(MSE): 5.200130860463793e-25\n",
            "PSNR:  290.9706608814422\n"
          ]
        }
      ],
      "source": [
        "#measure the quality of the image\n",
        "\n",
        "mse=mean_squared_error(np.array(oringinal_val),np.array(reconstructed_val))\n",
        "print(f'The Error in the construction(MSE): {mse}')\n",
        "\n",
        "Max=255\n",
        "PSNR = 20*np.log10(Max)-10*np.log10(mse)\n",
        "print(\"PSNR: \",PSNR)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
